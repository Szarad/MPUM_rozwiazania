{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qic-ui1CoF7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/1f/ea/664c589ec41b9e9ac6e20cc1fe9016f3913332d0dc5498a5d7771e2835af/grpcio-1.12.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting wheel>=0.26 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Collecting six>=1.10.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.13.3 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/3d/9c0a34ad8544abef864714840fb8954d630b04433f00881bc8fde7b2ab27/numpy-1.14.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl\n",
      "Collecting protobuf>=3.4.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/ad/ecd865eb1ba1ff7f6bd6bcb731a89d55bc0450ced8d457ed2d167c7b8d5f/protobuf-3.5.2.post1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from protobuf>=3.4.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/e1/820d941153923aac1d49d7fc37e17b6e73bfbd2904959fffbad77900cf92/setuptools-39.2.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six, grpcio, wheel, gast, absl-py, astor, numpy, html5lib, werkzeug, markdown, bleach, setuptools, protobuf, tensorboard, termcolor, tensorflow\n",
      "Successfully installed absl-py-0.2.2 astor-0.6.2 bleach-1.5.0 gast-0.2.0 grpcio-1.12.1 html5lib-0.9999999 markdown-2.6.11 numpy-1.14.4 protobuf-3.5.2.post1 setuptools-39.2.0 six-1.11.0 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.31.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "# Just some imports\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdRUB5WKquE3"
   },
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_1ACI7mr74H"
   },
   "source": [
    "MNIST is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
    "\n",
    "The MNIST database consists of 70000 grayscale digits, where each digit is an image with a size of 28x28 pixels.\n",
    "\n",
    "The datased is splitted into three subsets:\n",
    "\n",
    "\n",
    "1. Train set -- 55k images\n",
    "2. Test set -- 10k images\n",
    "3. Validation set -- 5k images\n",
    "\n",
    "\n",
    "TensorFlow package has already built-in functions to deal with the MNIST dataset. Below one can find how to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r8ULK8gSrLxc"
   },
   "outputs": [],
   "source": [
    "# Function for plotting the MNIST images\n",
    "def plot(image):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(28,28), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1519122206858,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "g816Ub6ZpCCI",
    "outputId": "63d2fd82-130c-4012-a9bb-8c639893e6a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-978bdd810a8d>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/karolinka/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/karolinka/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/karolinka/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/karolinka/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/karolinka/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2b_1O7awdZm"
   },
   "source": [
    "Now we can easily deal with the MNIST data, by using:\n",
    "\n",
    "\n",
    "1. mnist.train.images\n",
    "2. mnist.test.images\n",
    "3. mnist.validation.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1519122214294,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "-M8pQvH5rO7z",
    "outputId": "26ad77d7-8741-43ea-f4dc-2b09d0e456f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGES:\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(5000, 784)\n",
      "LABELS:\n",
      "(55000, 10)\n",
      "(10000, 10)\n",
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of images from each subset\n",
    "print (\"IMAGES:\")\n",
    "print (mnist.train.images.shape)\n",
    "print (mnist.test.images.shape)\n",
    "print (mnist.validation.images.shape)\n",
    "\n",
    "# Print the shapes of labels from each subset\n",
    "print (\"LABELS:\")\n",
    "print (mnist.train.labels.shape)\n",
    "print (mnist.test.labels.shape)\n",
    "print (mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dolBLdWcWmqG"
   },
   "source": [
    "As we can see, every image is now a 784 dimensional vector, as by default it is reshaped from the matrix of a size 28x28 pixels.\n",
    "\n",
    "Also we see that labels are 10 dimensional vectors, what is caused by the fact that they are in one-hot-encoding form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2686
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1519122219106,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "ZeUmb24leShM",
    "outputId": "0887e608-d3d1-4aa1-a6f3-3fd80dbaffc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the vector of sample training image\n",
    "mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1519122223123,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "MhUzPQoawZcw",
    "outputId": "493f1a72-2351-41e4-d54e-b385e5cd1b8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the sample training image\n",
    "plot(mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1519122225766,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "fgn9mdisZHUM",
    "outputId": "70e74195-a4eb-4793-b411-ad60c6f2b8bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the label of sample training image\n",
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xv7TNoX2dd9"
   },
   "source": [
    "# Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-263qjD9Wdi"
   },
   "source": [
    "TensorFlow is popular open-source deep learning library developed by Google.\n",
    "\n",
    "\\\\\n",
    "\n",
    "TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. \n",
    "\n",
    "A computational graph is a series of TensorFlow operations arranged into a graph. The graph is composed of two types of objects:\n",
    "\n",
    "\n",
    "*   Operations (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors.\n",
    "*   Tensors: The edges in the graph. These represent the values that will flow through the graph.\n",
    "\n",
    "\\\\\n",
    "\n",
    "This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n",
    "\n",
    "Dataflow has several advantages that TensorFlow leverages when executing your programs:\n",
    "\n",
    "\n",
    "*   Parallelism\n",
    "*   Distributed execution\n",
    "*   Compilation\n",
    "*   Portability\n",
    "\n",
    "\\\\\n",
    "\n",
    "We highly recommend to read the resources from the [following link](https://www.tensorflow.org/programmers_guide/), to understand the TF architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bisbqZ-Q3hZ7"
   },
   "source": [
    "## Session initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIXcFwtD-yz4"
   },
   "source": [
    "To evaluate tensors, instantiate a tf.Session object, informally known as a session. A session encapsulates the state of the TensorFlow runtime, and runs TensorFlow operations. If a tf.Graph is like a .py file, a tf.Session is like the python executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6fy3Es2o2clg"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-AI50Jp32hj"
   },
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Juuf-Ai15Utr"
   },
   "source": [
    "TensorFlow, is a framework to define and run computations involving tensors. A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes.\n",
    "\n",
    "\\\\\n",
    "\n",
    "TensorFlow programs work by first building a graph of tf.Tensor objects, detailing how each tensor is computed based on the other available tensors and then by running parts of this graph to achieve the desired results.\n",
    "\n",
    "\\\\\n",
    "\n",
    "tf.Tensor does not exist outside the context of a single session.run call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdW3amRS-AZ_"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AKUmh8bl31RU"
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0)\n",
    "node2 = tf.constant(4, dtype=tf.int32)\n",
    "node3 = tf.constant(0., name=\"Zero_tensor\")\n",
    "node4 = tf.constant([1., 2., 3.])\n",
    "node5 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "node6 = tf.ones([3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1519122375765,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "cQ1EEkjF3f4l",
    "outputId": "ab53910a-0586-4310-8a30-c957f32b5972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "\n",
      "4\n",
      "4\n",
      "\n",
      "Zero_tensor:0\n",
      "\n",
      "(3,)\n",
      "\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "Tensor(\"ones:0\", shape=(3, 3, 3), dtype=float32)\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(node1)\n",
    "print(type(node1))\n",
    "print()\n",
    "\n",
    "print(node2.eval())\n",
    "print(sess.run(node2))\n",
    "print()\n",
    "\n",
    "print(node3.name)\n",
    "print()\n",
    "\n",
    "print(node4.shape)\n",
    "print()\n",
    "\n",
    "print(node5.eval())\n",
    "print()\n",
    "\n",
    "print(node6)\n",
    "print(sess.run(node6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnQevLMq-ClJ"
   },
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1519122500713,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "WkZbo8lz2dQd",
    "outputId": "7fda4938-caba-4535-8e62-37a6e966f45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "5.0\n",
      "\n",
      "Tensor(\"our_add_node:0\", shape=(), dtype=float32)\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.)\n",
    "y = tf.constant(3.)\n",
    "\n",
    "add_1 = x + y\n",
    "add_2 = tf.add(x, y, name='our_add_node')\n",
    "\n",
    "print(add_1)\n",
    "print(add_1.eval())\n",
    "print()\n",
    "\n",
    "print(add_2)\n",
    "print(add_2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1519122575549,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "L4m7teEk_58o",
    "outputId": "770c0e9e-f72c-424e-b4a3-ddebfa7ed1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_1:0\", shape=(3,), dtype=float32)\n",
      "[5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.)\n",
    "y = tf.constant([3., 4., 5.])\n",
    "\n",
    "add_3 = x + y\n",
    "\n",
    "print(add_3)\n",
    "print(add_3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1519122588556,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "5TpYmOUEBBcn",
    "outputId": "f86efd5a-9e70-4e95-b98d-f3a2a4039068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(100, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "xx = tf.random_normal(shape=(100, 10), name='xx')\n",
    "yy = tf.random_normal(shape=(10, 2), name='yy')\n",
    "\n",
    "xyxy = tf.matmul(xx, yy)\n",
    "\n",
    "print(xyxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApkVpalR6anH"
   },
   "source": [
    "### Tensor does not exist outside the context of a single session.run call\n",
    "\n",
    "The result shows a different random value on each call to run, but a consistent value during a single run (out1 and out2 receive the same random input):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1519122644532,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "scdKr0-Z6a-1",
    "outputId": "1a25dec7-8900-4e4d-c166-f2334e7c1e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32856107 0.76389205 0.45400012]\n",
      "[0.85200894 0.9873638  0.9982232 ]\n",
      "(array([1.8682148, 1.9791001, 1.5944145], dtype=float32), array([2.8682148, 2.9791002, 2.5944145], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toETfx7lCgfj"
   },
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pIAIku-SEG"
   },
   "source": [
    "A placeholder represents an entry point for us to feed actual data values\n",
    "into tensors. It is not initialized and contains no data. A placeholder\n",
    "generates an error if it is executed without a feed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8YIfOQriNso"
   },
   "source": [
    "#### Placeholder for a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lT_CVj_gCi8-"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[1,1])\n",
    "y = tf.matmul(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r-sP4AaACjMw"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-ec0731bab3f8>\", line 1, in <module>\n    x = tf.placeholder(tf.float32, shape=[1,1])\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-921d4d91d90a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" A placeholder generates an error if it is executed without a feed \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ERROR: will fail because x was not fed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-ec0731bab3f8>\", line 1, in <module>\n    x = tf.placeholder(tf.float32, shape=[1,1])\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" A placeholder generates an error if it is executed without a feed \"\"\"\n",
    "print(sess.run(y))  # ERROR: will fail because x was not fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1519122866690,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "GYwBsVOyCjGb",
    "outputId": "367d40fe-0d32-43c1-9fbd-4753353f5a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.]]\n"
     ]
    }
   ],
   "source": [
    "number = [[3.]]\n",
    "print(sess.run(y, feed_dict={x: number}))  # Will succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBlRmIFAjMRY"
   },
   "source": [
    "#### Placeholder for a tensor with undefined length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_AOiK4vTjRny"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "y = x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1519122973337,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "ZjhaSI8TjxCH",
    "outputId": "cedb27cb-c579-43f7-b696-4be2b58a3497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]]\n",
      "\n",
      "[[2. 2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "tensor = np.ones((1, 5))\n",
    "print(tensor)\n",
    "print()\n",
    "print(sess.run(y, feed_dict={x: tensor}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjkiD-gbA_ti"
   },
   "source": [
    "#### Operations on placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lWjTpu68BA1n"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[1, None])\n",
    "y = tf.placeholder(tf.float32, shape=[1, None])\n",
    "\n",
    "z_1 = x + y\n",
    "z_2 = tf.matmul(x, tf.transpose(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1519123027608,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "3h91PyebBAta",
    "outputId": "e2d20df2-e4cf-46ac-d821-f690368bce75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 14. 16.]]\n",
      "\n",
      "[[74.]]\n"
     ]
    }
   ],
   "source": [
    "x_tensor = [[1., 2., 3.]]\n",
    "y_tensor = [[11., 12., 13.]]\n",
    "print(sess.run(z_1, feed_dict={x: x_tensor, y: y_tensor}))\n",
    "print()\n",
    "print(sess.run(z_2, feed_dict={x: x_tensor, y: y_tensor}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5O10bIyuBKqP"
   },
   "source": [
    "## Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shNMrgqb-eQa"
   },
   "source": [
    "A TensorFlow variable is the best way to represent the state manipulated\n",
    "by your program. A tf.Variable represents a tensor whose value can be\n",
    "changed by running ops on it.\n",
    "Internally, a tf.Variable stores a tensor. Specific ops allow you to read and\n",
    "modify the values of this tensor.\n",
    "\n",
    "\\\\\n",
    "\n",
    "Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d7Vhb-JGBPrM"
   },
   "outputs": [],
   "source": [
    "var_1 = tf.get_variable(\"var_1\", shape=[2, 3]) # default type tf.float32, default init tf.glorot_uniform_initializer\n",
    "var_2 = tf.get_variable(\"var_2\", shape=[5], initializer=tf.constant_initializer(1000.))\n",
    "var_3 = tf.get_variable(\"var_3\", shape=[3, 3, 3], initializer=tf.initializers.random_normal())\n",
    "\n",
    "var_4 = tf.Variable(tf.constant(3., shape=[1, 2]))\n",
    "var_5 = tf.Variable(tf.random_normal([2, 1]))\n",
    "var_6 = tf.Variable(tf.random_uniform([1, 1]), name=\"var_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c1SYbbUv4TvQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var_1:0' shape=(2, 3) dtype=float32_ref>\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value var_1\n\t [[Node: _retval_var_1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](var_1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value var_1\n\t [[Node: _retval_var_1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](var_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d637e93c1edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" Before you can use a variable, it must be initialized!!! \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ERROR: will fail because variables are not initialized!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \"\"\"\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5178\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5180\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value var_1\n\t [[Node: _retval_var_1_0_0 = _Retval[T=DT_FLOAT, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](var_1)]]"
     ]
    }
   ],
   "source": [
    "\"\"\" Before you can use a variable, it must be initialized!!! \"\"\"\n",
    "print(var_1)\n",
    "print(var_1.eval()) # ERROR: will fail because variables are not initialized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZA6mr_p_BPiB"
   },
   "outputs": [],
   "source": [
    "\"\"\" Before you can use a variable, it must be initialized!!! \"\"\"\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1519123335342,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "tvtfr_o53hHk",
    "outputId": "a57eefb0-a1df-490b-fad4-b41a8a1cf6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var_1:0' shape=(2, 3) dtype=float32_ref>\n",
      "[[ 0.6339016  -0.85074687 -0.40628666]\n",
      " [-0.13980776  1.0913789   0.1443994 ]]\n",
      "\n",
      "<tf.Variable 'var_2:0' shape=(5,) dtype=float32_ref>\n",
      "[1000. 1000. 1000. 1000. 1000.]\n",
      "\n",
      "<tf.Variable 'var_3:0' shape=(3, 3, 3) dtype=float32_ref>\n",
      "[[[ 0.173098   -0.7522116   0.53066134]\n",
      "  [ 0.36987022  0.94048494 -0.71320784]\n",
      "  [ 1.9105393   0.7954687  -0.44640672]]\n",
      "\n",
      " [[-0.9223671  -0.8734648   0.36734757]\n",
      "  [-0.68438435  0.19258565 -2.2917182 ]\n",
      "  [-0.02112285  1.7471564  -0.9517774 ]]\n",
      "\n",
      " [[ 2.4070487  -0.33092928 -0.82059413]\n",
      "  [ 0.40101963 -1.0287039  -0.24965385]\n",
      "  [-0.12046738  0.33668953 -1.3680288 ]]]\n",
      "\n",
      "<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32_ref>\n",
      "[[3. 3.]]\n",
      "\n",
      "<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\n",
      "[[-2.6204815 ]\n",
      " [-0.51063406]]\n",
      "\n",
      "<tf.Variable 'var_6:0' shape=(1, 1) dtype=float32_ref>\n",
      "[[0.98330724]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(var_1)\n",
    "print(var_1.eval())\n",
    "print()\n",
    "\n",
    "print(var_2)\n",
    "print(var_2.eval())\n",
    "print()\n",
    "\n",
    "print(var_3)\n",
    "print(sess.run(var_3))\n",
    "print()\n",
    "\n",
    "print(var_4)\n",
    "print(sess.run(var_4))\n",
    "print()\n",
    "\n",
    "print(var_5)\n",
    "print(sess.run(var_5))\n",
    "print()\n",
    "\n",
    "print(var_6)\n",
    "print(var_6.eval())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qigzSVW-7Pqi"
   },
   "source": [
    "### Variable exists outside the context of a single session.run call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1519123388589,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "oYwt-lAf7QHo",
    "outputId": "630116cc-989a-4289-f263-90168a671dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9746403  0.8640773 -1.0308193]\n",
      "[ 0.9746403  0.8640773 -1.0308193]\n",
      "(array([ 1.9746404,  1.8640773, -0.0308193], dtype=float32), array([2.9746404, 2.8640773, 0.9691807], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "vec = tf.get_variable(\"vec\", shape=(3,), initializer=tf.initializers.random_normal())\n",
    "sess.run(tf.global_variables_initializer())\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_29uYo87Qwt"
   },
   "source": [
    "### Computing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bDtQynMZ_bJa"
   },
   "outputs": [],
   "source": [
    "var_7 = tf.matmul(var_4, var_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1519123622651,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "IS7tYaK__SBv",
    "outputId": "86350a39-ea83-4c90-d302-d96230f2a136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients/MatMul_3_grad/MatMul:0' shape=(1, 2) dtype=float32>, <tf.Tensor 'gradients/MatMul_3_grad/MatMul_1:0' shape=(2, 1) dtype=float32>]\n",
      "[[1.0435681 0.6223902]]\n",
      "[[3.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "g = tf.gradients(var_7, [var_4, var_5])\n",
    "print(g)\n",
    "print(g[0].eval())\n",
    "print(g[1].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1519123654782,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "V_eatiVgCRCX",
    "outputId": "241d6c5d-415b-49e7-b83b-db7d1e7606d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients_1/MatMul_4_grad/MatMul:0' shape=(2, 1) dtype=float32>, <tf.Tensor 'gradients_1/MatMul_4_grad/MatMul_1:0' shape=(1, 2) dtype=float32>]\n",
      "[[6.]\n",
      " [6.]]\n",
      "[[4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "x_1 = tf.constant(2., shape=[2,1])\n",
    "x_2 = tf.constant(3., shape=[1,2])\n",
    "y = tf.matmul(x_1, x_2)\n",
    "\n",
    "g = tf.gradients(y, [x_1, x_2])\n",
    "print(g)\n",
    "print(g[0].eval())\n",
    "print(g[1].eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6m-uRp4ABGsR"
   },
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yf7rqwFFhv5-"
   },
   "source": [
    "In TensorFlow one can use fast, efficient gradient optimizers to minimize the given function. \\\\\n",
    "In the following example we will show how to use optimizers in TF, by minimizing x^2 function, with using of the Gradient Decent Optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiEPD-owirIv"
   },
   "source": [
    "#### Defining the starting point x and the function y = x^2\n",
    "\n",
    "Notice, that the starting point should be initialized as a variable, not a tensor, as the optimizer have to change its value, by repeatedly subtracting the gradient of function in order to minimize y value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FkIlIp87BQlg"
   },
   "outputs": [],
   "source": [
    "x = tf.get_variable(\"opt_x\", dtype=tf.float32, initializer=tf.constant_initializer(1000.), shape=[1, 1])\n",
    "y = tf.pow(x, [2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsRMKuqHjvvb"
   },
   "source": [
    "#### Defining the Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xdGNRmjMBQdg"
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MrgPHWVDkH9u"
   },
   "source": [
    "#### Iterate to minimize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1519123914773,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "cg639E8fB-8Y",
    "outputId": "ec520bef-fea8-4768-8f92-52f2e23889b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[1000.]]\n",
      "y =  [[1000000.]]\n",
      "[[800.]]\n",
      "[[85.89934]]\n",
      "[[9.2233715]]\n",
      "[[0.99035203]]\n",
      "[[0.10633824]]\n",
      "[[0.01141798]]\n",
      "[[0.001226]]\n",
      "[[0.00013164]]\n",
      "[[1.4134782e-05]]\n",
      "[[1.5177106e-06]]\n",
      "[[1.6296293e-07]]\n",
      "[[1.7498012e-08]]\n",
      "[[1.8788346e-09]]\n",
      "[[2.0173833e-10]]\n",
      "[[2.1661489e-11]]\n",
      "[[2.3258847e-12]]\n",
      "[[2.4973995e-13]]\n",
      "[[2.6815621e-14]]\n",
      "[[2.8793051e-15]]\n",
      "[[3.0916303e-16]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  print(\"x = \", x.eval())\n",
    "  print(\"y = \", y.eval())\n",
    "  for i in range(200):\n",
    "      train_step.run()\n",
    "      if i % 10 == 0:\n",
    "        print(x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 527,
     "status": "error",
     "timestamp": 1519124031486,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "5l6ZkbE8BzLH",
    "outputId": "43a8ee03-1411-4bef-a925-36e81f15dde5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'var_1:0' shape=(2, 3) dtype=float32_ref>\", \"<tf.Variable 'var_2:0' shape=(5,) dtype=float32_ref>\", \"<tf.Variable 'var_3:0' shape=(3, 3, 3) dtype=float32_ref>\", \"<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'var_6:0' shape=(1, 1) dtype=float32_ref>\", \"<tf.Variable 'vec:0' shape=(3,) dtype=float32_ref>\", \"<tf.Variable 'opt_x:0' shape=(1, 1) dtype=float32_ref>\"] and loss Tensor(\"Pow_1:0\", shape=(1,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3091d36536e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ERROR: there are no gradients provided for any variable!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/karolinka/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    419\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'var_1:0' shape=(2, 3) dtype=float32_ref>\", \"<tf.Variable 'var_2:0' shape=(5,) dtype=float32_ref>\", \"<tf.Variable 'var_3:0' shape=(3, 3, 3) dtype=float32_ref>\", \"<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'var_6:0' shape=(1, 1) dtype=float32_ref>\", \"<tf.Variable 'vec:0' shape=(3,) dtype=float32_ref>\", \"<tf.Variable 'opt_x:0' shape=(1, 1) dtype=float32_ref>\"] and loss Tensor(\"Pow_1:0\", shape=(1,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "\"\"\" Optimizer needs variables that can be mutated in order to minimize a function! \"\"\"\n",
    "x = tf.constant(1000.)\n",
    "y = tf.pow(x, [2.])\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(y) # ERROR: there are no gradients provided for any variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdCuaZ8izHMc"
   },
   "source": [
    "# Softmax regression for MNIST classification\n",
    "\n",
    "Example of the softmax regression applied to MNIST digits classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rS9AjgddyJH"
   },
   "source": [
    "## Building the softmax architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88o1OpYSe_m0"
   },
   "source": [
    "#### Create placeholders for training data. \n",
    "\n",
    "Remember about a propper shape of training images (in mnist.train.images every digit is a 784D vector) and labels (In training dataset labels are in one-hot-encoding form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aISYxnHn1gfK"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_labels = tf.placeholder(tf.float32, [None,10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJ843acDfSsw"
   },
   "source": [
    "#### Initialize weight matrix and biases vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qghs2HpezLIq"
   },
   "outputs": [],
   "source": [
    "W = tf.get_variable(\"softmax_W\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=np.array([784, 10]))\n",
    "b = tf.get_variable(\"softmax_b\",dtype=tf.float32,initializer=tf.constant_initializer(0.2), shape=np.array([10]))\n",
    "#W = tf.get_variable(\"softmax_W\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=[784, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gu_qgY9KgHYj"
   },
   "source": [
    "#### Define classificator\n",
    "\n",
    "Multiply input image by a weighr matrix, them add biases and apply softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JB0E5g54zK_s"
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFNyGJQvd6UE"
   },
   "source": [
    "## Softmax training\n",
    "\n",
    "We will now train the softmax classifier. For this purpose we have to define the loss function, cross entropy in this example and optimizer, we will use Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GY32Cx4seYIw"
   },
   "source": [
    "#### Define the loss function\n",
    "\n",
    "Here we define the cross entropy loss function by hand, but one should notice, that better option is to use the tf.nn.softmax_cross_entropy_with_logits_v2 function, as this is more numerically stable solution (as we are taking the log of softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kiM0GFWu1l1F"
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(input_tensor=y_labels*tf.log(y),reduction_indices=[1]) \n",
    "#cross_entropy=-tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_labels, logits=y))\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7beUJW_edAC"
   },
   "source": [
    "#### Define the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FheaU2To2Y0R"
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcpuOTFAeh2m"
   },
   "source": [
    "#### Check whether softmax classifier returns correct predictions and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OKFShUFh2xz3"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create a vector that tells us, whether the predictions from our net - y_conv\n",
    "    are equal to the correct digit labels - y. \"\"\"\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_labels, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "\n",
    "\"\"\" Calculate the accurracy of correct predictions \"\"\"\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12lEKUb1en1o"
   },
   "source": [
    "#### Training the network\n",
    "\n",
    "The following code will train our network with using of our predefined SGD optimizer, based on the batch size equal to 64 and with 2000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3920,
     "status": "ok",
     "timestamp": 1519125008435,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "GRZpPzEr2Z2h",
    "outputId": "5af184d8-9244-4e18-c1ec-fcfe78dfbc35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, validation accuracy: 0.11299999803304672\n",
      "step: 100, validation accuracy: 0.8519999980926514\n",
      "step: 200, validation accuracy: 0.875\n",
      "step: 300, validation accuracy: 0.8859999775886536\n",
      "step: 400, validation accuracy: 0.890999972820282\n",
      "step: 500, validation accuracy: 0.8970000147819519\n",
      "step: 600, validation accuracy: 0.902999997138977\n",
      "step: 700, validation accuracy: 0.902999997138977\n",
      "step: 800, validation accuracy: 0.9049999713897705\n",
      "step: 900, validation accuracy: 0.9079999923706055\n",
      "step: 1000, validation accuracy: 0.9100000262260437\n",
      "step: 1100, validation accuracy: 0.9079999923706055\n",
      "step: 1200, validation accuracy: 0.9110000133514404\n",
      "step: 1300, validation accuracy: 0.9129999876022339\n",
      "step: 1400, validation accuracy: 0.9120000004768372\n",
      "step: 1500, validation accuracy: 0.9120000004768372\n",
      "step: 1600, validation accuracy: 0.9150000214576721\n",
      "step: 1700, validation accuracy: 0.9160000085830688\n",
      "step: 1800, validation accuracy: 0.9160000085830688\n",
      "step: 1900, validation accuracy: 0.9160000085830688\n",
      "test accuracy: 0.9150000214576721\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(2000):\n",
    "    # Get the batch with 64 images from the MNIST training set\n",
    "    batch = mnist.train.next_batch(64)\n",
    "\n",
    "    # Fill data into placeholders and run the training step\n",
    "    train_step.run(feed_dict={x: batch[0], y_labels: batch[1]})\n",
    "\n",
    "    # Print the validation accuracy every 100 steps\n",
    "    if i % 100 == 0:\n",
    "      validation_accuracy = accuracy.eval(feed_dict={\n",
    "          x: mnist.validation.images, y_labels: mnist.validation.labels})\n",
    "      print('step: {}, validation accuracy: {}'.format(i, round(validation_accuracy, 3)))\n",
    "\n",
    "\n",
    "  # Print the test set accuracy\n",
    "  print('test accuracy: {}'.format(round(accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images, y_labels: mnist.test.labels}), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOCFFgLT5_JH"
   },
   "source": [
    "# Simple Feed Forward Network for MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRSvm46Hdpc1"
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNbv2gq0UQV6"
   },
   "source": [
    "Exercise:\n",
    "\n",
    "\n",
    "Create the Fully Connected Feed Forward Network for digits classification, with the following architecture:\n",
    "\n",
    "\n",
    "1.   First layer, that maps one grayscale image (of size 28x28 = 784 pixels) to 100 hidden neurons.\n",
    "2.   Second layer, that maps 100 features into another 100 hidden neurons.\n",
    "3.   Third layer, that maps 100 features into another 100 hidden neurons.\n",
    "4.   Last layer, that maps 100 features to 10 classes, one for each digit.\n",
    "\n",
    "\n",
    "In every hidden layer, we should use the ReLU activation function. Softmax should be applied on the last layer of our network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBoAGguIW5Pr"
   },
   "source": [
    "#### Create placeholders for training data. \n",
    "\n",
    "Remember about a propper shape of training images (in mnist.train.images every digit is a 784D vector) and labels (In training dataset labels are in one-hot-encoding form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iuNLg3sG5_-Z"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create a placeholders for MNIST images and their labels \"\"\"\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_labels = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QIoyNUoZlKk"
   },
   "source": [
    "#### Initialize weight matrices and biases for all layers of our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "me1-LMaI7lpX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize weights matrix W and biases b for the first hidden layer (matrix should map 784 input features into 100 features) \"\"\"\n",
    "W_1 = tf.get_variable(\"softmax_W1\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=[784, 100])\n",
    "b_1 = tf.get_variable(\"softmax_b1\", dtype=tf.float32, initializer=tf.constant_initializer(0.2), shape=[100])\n",
    "\n",
    "\"\"\" Initialize weights matrix W and biases b for the second hidden layer (matrix should map 100 features into 100 features) \"\"\"\n",
    "W_2 = tf.get_variable(\"softmax_W2\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=[100, 100])\n",
    "b_2 = tf.get_variable(\"softmax_b2\", dtype=tf.float32, initializer=tf.constant_initializer(0.2), shape=[100])\n",
    "\n",
    "\"\"\" Initialize weights matrix W and biases b for the third hidden layer (matrix should map 100 features into 100 features) \"\"\"\n",
    "W_3 = tf.get_variable(\"softmax_W3\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=[100, 100])\n",
    "b_3 = tf.get_variable(\"softmax_b3\", dtype=tf.float32, initializer=tf.constant_initializer(0.2), shape=[100])\n",
    "\n",
    "\"\"\" Initialize weights matrix W and biases b for the output layer (matrix should map 100 features into 10 digits classes) \"\"\"\n",
    "W_4 = tf.get_variable(\"softmax_W4\", dtype=tf.float32, initializer=tf.initializers.truncated_normal(stddev=0.05), shape=[100, 10])\n",
    "b_4 = tf.get_variable(\"softmax_b4\", dtype=tf.float32, initializer=tf.constant_initializer(0.2), shape=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6XudNN7bV6K"
   },
   "source": [
    "#### Define network operations\n",
    "\n",
    "In every hidden layer, we should use the ReLU activation function (tf.nn.relu). \\\\\n",
    "Softmax should be applied on the last layer of our network (tf.nn.softmax).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iGm85o9D7opg"
   },
   "outputs": [],
   "source": [
    "\"\"\" Define output from the first layer (using W_1 and b_1) \"\"\"\n",
    "y = tf.nn.relu(tf.matmul(x, W_1) + b_1)\n",
    "\n",
    "\"\"\" Define output from the second layer (using W_2 and b_2) \"\"\"\n",
    "y =  tf.nn.relu(tf.matmul(y, W_2) + b_2)\n",
    "\n",
    "\"\"\" Define output from the third layer (using W_3 and b_3) \"\"\"\n",
    "y = tf.nn.relu(tf.matmul(y,W_3) + b_3)\n",
    "\n",
    "\"\"\" Define output from the last layer (using W_4 and b_4) --> this will give us predictions  \"\"\"\n",
    "y = tf.nn.softmax(tf.matmul(y, W_4) + b_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYENz7r8Wc6h"
   },
   "source": [
    "## Network training\n",
    "\n",
    "We will now try to train our network. For this purpose we have to define the loss function, cross entropy in this example and optimizer, we will use Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rfdo9K7LWh1m"
   },
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n",
    "This time try to use numerically stable version of softmax, given by a function 'tf.nn.softmax_cross_entropy_with_logits_v2', instead of writing it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wvz7BXvu7ojG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Define the cross entropy error between true and predicted labels \"\"\"\n",
    "cross_entropy=tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_labels, logits=y)\n",
    "#cross_entropy=-tf.reduce_sum(input_tensor=y_labels*tf.log(y),reduction_indices=[1]) \n",
    "cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WY8FSEQ57occ"
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvuWkFfMV1CG"
   },
   "source": [
    "#### Check whether our network returns correct predictions and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_yFsTr3r7oU9"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create a vector that tells us, whether the predictions from our net - y_conv\n",
    "    are equal to the correct digit labels - y. \"\"\"\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_labels, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "\n",
    "\"\"\" Calculate the accurracy of correct predictions \"\"\"\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1ATln5RWo8U"
   },
   "source": [
    "#### Training the network\n",
    "\n",
    "The following code will train our network with using of our predefined Adam optimizer, based on the batch size equal to 64 and with 5000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13456,
     "status": "ok",
     "timestamp": 1519126303878,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "a2np_IRo7oNh",
    "outputId": "eb5299a9-95f1-491f-9d15-6c3ba91d6a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, validation accuracy: 0.10000000149011612\n",
      "step: 100, validation accuracy: 0.8349999785423279\n",
      "step: 200, validation accuracy: 0.8920000195503235\n",
      "step: 300, validation accuracy: 0.8930000066757202\n",
      "step: 400, validation accuracy: 0.9020000100135803\n",
      "step: 500, validation accuracy: 0.9049999713897705\n",
      "step: 600, validation accuracy: 0.925000011920929\n",
      "step: 700, validation accuracy: 0.9259999990463257\n",
      "step: 800, validation accuracy: 0.9300000071525574\n",
      "step: 900, validation accuracy: 0.9330000281333923\n",
      "step: 1000, validation accuracy: 0.9359999895095825\n",
      "step: 1100, validation accuracy: 0.9330000281333923\n",
      "step: 1200, validation accuracy: 0.9300000071525574\n",
      "step: 1300, validation accuracy: 0.9409999847412109\n",
      "step: 1400, validation accuracy: 0.9490000009536743\n",
      "step: 1500, validation accuracy: 0.949999988079071\n",
      "step: 1600, validation accuracy: 0.9449999928474426\n",
      "step: 1700, validation accuracy: 0.9490000009536743\n",
      "step: 1800, validation accuracy: 0.9490000009536743\n",
      "step: 1900, validation accuracy: 0.9409999847412109\n",
      "step: 2000, validation accuracy: 0.9549999833106995\n",
      "step: 2100, validation accuracy: 0.9559999704360962\n",
      "step: 2200, validation accuracy: 0.9559999704360962\n",
      "step: 2300, validation accuracy: 0.9430000185966492\n",
      "step: 2400, validation accuracy: 0.9559999704360962\n",
      "step: 2500, validation accuracy: 0.953000009059906\n",
      "step: 2600, validation accuracy: 0.9559999704360962\n",
      "step: 2700, validation accuracy: 0.9559999704360962\n",
      "step: 2800, validation accuracy: 0.9580000042915344\n",
      "step: 2900, validation accuracy: 0.9599999785423279\n",
      "step: 3000, validation accuracy: 0.9589999914169312\n",
      "step: 3100, validation accuracy: 0.9549999833106995\n",
      "step: 3200, validation accuracy: 0.9589999914169312\n",
      "step: 3300, validation accuracy: 0.9559999704360962\n",
      "step: 3400, validation accuracy: 0.9470000267028809\n",
      "step: 3500, validation accuracy: 0.9549999833106995\n",
      "step: 3600, validation accuracy: 0.9629999995231628\n",
      "step: 3700, validation accuracy: 0.9629999995231628\n",
      "step: 3800, validation accuracy: 0.9639999866485596\n",
      "step: 3900, validation accuracy: 0.9589999914169312\n",
      "step: 4000, validation accuracy: 0.9599999785423279\n",
      "step: 4100, validation accuracy: 0.9570000171661377\n",
      "step: 4200, validation accuracy: 0.9670000076293945\n",
      "step: 4300, validation accuracy: 0.9570000171661377\n",
      "step: 4400, validation accuracy: 0.9679999947547913\n",
      "step: 4500, validation accuracy: 0.9649999737739563\n",
      "step: 4600, validation accuracy: 0.9639999866485596\n",
      "step: 4700, validation accuracy: 0.9649999737739563\n",
      "step: 4800, validation accuracy: 0.9589999914169312\n",
      "step: 4900, validation accuracy: 0.9649999737739563\n",
      "test accuracy: 0.9610000252723694\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(5000):\n",
    "    # Get the batch with 64 images from the MNIST training set\n",
    "    batch = mnist.train.next_batch(64)\n",
    "    #print(batch_x)\n",
    "    # Fill data into placeholders\n",
    "    train_step.run(feed_dict={x: batch[0], y_labels:batch[1]})\n",
    "\n",
    "    # Print the validation accuracy every 100 steps\n",
    "    if i % 100 == 0:\n",
    "      validation_accuracy = accuracy.eval(feed_dict={\n",
    "          x: mnist.validation.images, y_labels: mnist.validation.labels})\n",
    "      print('step: {}, validation accuracy: {}'.format(i, round(validation_accuracy, 3)))\n",
    "\n",
    "\n",
    "  # Print the test set accuracy\n",
    "  print('test accuracy: {}'.format(round(accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images, y_labels: mnist.test.labels}), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4958-YRqSI-"
   },
   "source": [
    "# Convolutional Neural Network for MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XeJkuR15VDj_"
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reHRRPUHk7FV"
   },
   "source": [
    "Exercise:\n",
    "\n",
    "Create the CNN for digits classification, with the following architecture:\n",
    "\n",
    "\n",
    "1.   First convolutional layer, that maps one grayscale image to 32 feature maps.\n",
    "2.   Second convolutional layer, that maps 32 feature maps to 64 feature maps.\n",
    "3.   Fully connected layer 1, that maps our 64 feature maps into one layer, with 1024 features.\n",
    "4.   Fully connected layer 2, that maps the 1024 features to 10 classes, one for each digit\n",
    "\n",
    "Use filters with width and height equal to 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvfwSRadongm"
   },
   "source": [
    "#### At the beggining we have to create some auxiliary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "atNG8IgVo5B9"
   },
   "outputs": [],
   "source": [
    "def get_weight_variable(shape):\n",
    "  \"\"\"\n",
    "  Write a function, that will return the tf.Variable of specified shape, with\n",
    "  coefficients initialized by random, sampled from a normal distribution with\n",
    "  mean = 0 and sd = 0.02\n",
    "  \"\"\"\n",
    "  init = tf.random_normal(shape,mean=0, stddev=0.02)\n",
    "  return tf.Variable(init)\n",
    "\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "  \"\"\"\n",
    "  Write a function, that will return the result of a convolution between\n",
    "  a tensor x and a weight vector W. We recommend using strides equal to 1\n",
    "  in every direction and use SAME padding.\n",
    "  \"\"\"\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  \"\"\"\n",
    "  Write a function, that will return the result of max pooling operation done\n",
    "  on a tensor x, that will reduce the size of inner image. \n",
    "  The length and width of a pooling layer window should be equal to 2.\n",
    "  \"\"\"\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], \n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LJASUEUUZK1"
   },
   "source": [
    "#### Create placeholders for training data.\n",
    "\n",
    "Remember about a propper shape of training images (in mnist.train.images every digit is a 784D vector) and labels (In training dataset labels are in one-hot-encoding form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "z6ItZS1rpCOe"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_l = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEBF4aHIXxxa"
   },
   "source": [
    "#### Reshape the x vector into a rank 4 tensor with shapes: [batch_size, rows, columnss, colors/filters]. Keep in mind, that we should have 28x28 image, with only one color (as the image is in grayscale) and that batch size will be given later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LCVImfFordmU"
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1]) # [b_size, rows, cols, colors/filters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yy-6MB2rkMMb"
   },
   "source": [
    "#### Create first convolutional layer, that will map one grayscale image into 32 feature maps. To do so, we will use 32 convolutional filters with sizes 5x5x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HmWTYyK3rdhv"
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize weights matrix W \"\"\"\n",
    "W_conv1 = get_weight_variable([5, 5, 1, 32]) # 32 filters with size 5x5x1\n",
    "\n",
    "\"\"\" Initialize biases vector \"\"\"\n",
    "b_conv1 = get_weight_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WoG5Q-Syrdcl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(5, 5, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Apply convolution operation between image and weights, then add bias and apply relu function \"\"\"\n",
    "y = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # [batch_size, 28, 28, 32]\n",
    "print(x_image.shape)\n",
    "print(W_conv1.shape)\n",
    "\"\"\" Apply max pooling operation on h_conv1 \"\"\"\n",
    "y = max_pool_2x2(y) # [batch_size, 14, 14, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3AKLlmbVxXpj"
   },
   "source": [
    "#### Create second convolutional layer, that will map resulted 32 feature maps into 64 features maps. To do so, we will use 64 convolutional filters with sizes 5x5x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BBxMYoFVrdWb"
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize weights matrix W \"\"\"\n",
    "W_conv2 =get_weight_variable([5, 5, 32, 64]) ### 64 filters with size 5x5x32\n",
    "\n",
    "\"\"\" Initialize biases vector b \"\"\"\n",
    "b_conv2 = get_weight_variable([64]) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "C2yd_IGaxlgj"
   },
   "outputs": [],
   "source": [
    "\"\"\" Apply convolution operation between image and weights, then add bias and apply relu function \"\"\"\n",
    "y = tf.nn.relu(conv2d(y, W_conv2) + b_conv2) ### \n",
    "\n",
    "\"\"\" Apply max pooling operation on h_conv1 \"\"\"\n",
    "y = max_pool_2x2(y) ### [batch_size, 7, 7, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7qHA40KyOaD"
   },
   "source": [
    "#### Create first fully connected layer -- after 2 rounds of downsampling, our 28x28 image is down to 7x7x64 feature maps -- now map this to 1024 features, with using of fully connected layer, with ReLU activation function and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wht3fwJxyPB6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_9:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Reshape_9:0\", shape=(?, 3136), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize weights matrix W, which maps 7x7x64 feature maps into one layer with 1024 features \"\"\"\n",
    "W_fc1 = get_weight_variable([7*7*64, 1024])\n",
    "\n",
    "\"\"\" Initialize biases vector b \"\"\"\n",
    "b_fc1 = get_weight_variable([1024])\n",
    "\n",
    "\"\"\" Reshape the result from the last convolutional layer from [batch_size, 7, 7, 64] to [batch_size, 7*7*64],\n",
    "    as this is the shape that is expected by the weight matrix W_fc1. \"\"\"\n",
    "print(y)\n",
    "y_flat = tf.reshape(y, [-1,7*7*64])\n",
    "print(y_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "43QWuAELTEin"
   },
   "outputs": [],
   "source": [
    "\"\"\" Apply matrix multiplication between image and weights, then add bias and apply relu function \"\"\"\n",
    "h_fc1 = tf.nn.relu(tf.matmul(y_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LjM4vDnVUJYx"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create placeholder for the dropout probability \"\"\"\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\"\"\" Apply dropout with probability = keep_prob \"\"\"\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pwl8o9EU_PS"
   },
   "source": [
    "#### Create the second convolutional layer, that maps 1024 features from the last layer into 10 classes, one for each digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQhjbZ6bWcmH"
   },
   "source": [
    "The softmax function applied on the result of this layer *y_conv* will give us the probabilities for every class that our convolutional neural network gives for the given image. Although we won't use this function at the moment, as this could be numerically unstable. We will handle this problem during the training step. At the moment we want to keep only logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N87axhCtU-s8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_38:0' shape=(1024, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_39:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize weights matrix W, which maps 1024 features into one layer with 10 features \"\"\"\n",
    "W_fc2 = get_weight_variable([1024, 10])\n",
    "print(W_fc2)\n",
    "\n",
    "\"\"\" Initialize biases vector b \"\"\"\n",
    "b_fc2 = get_weight_variable([10])\n",
    "print(b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hE4BywxYVrKf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_4/mul:0\", shape=(?, 1024), dtype=float32)\n",
      "<tf.Variable 'Variable_38:0' shape=(1024, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Apply matrix multiplication between image and weights, then add bias to get logits \"\"\"\n",
    "print(h_fc1_drop)\n",
    "print(W_fc2)\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzkjDw7wXil8"
   },
   "source": [
    "## Network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j80E1kqQXtqT"
   },
   "source": [
    "We will now try to train our network. For this purpose we have to define the loss function, cross entropy in this example and optimizer, we will use Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyuwoGqXYWgN"
   },
   "source": [
    "#### Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wqpeZX68Xovk"
   },
   "outputs": [],
   "source": [
    "\"\"\" Define the cross entropy loss function\n",
    "    Remember that in the return from our network - 'y_conv', we didn't use the softmax function to overcome problems\n",
    "    with numerical stability, that's why we should use now the function named softmax_cross_entropy_with_logits_v2, that\n",
    "    is more numerical stable. \"\"\"\n",
    "#cross_entropy=-tf.reduce_sum(input_tensor=y_l*tf.log(y_conv),reduction_indices=[1])\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_l, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hlqJyw1oYl8C"
   },
   "outputs": [],
   "source": [
    "\"\"\" Define the Adam optimizer with parameter equal to 1e-3, that will minimize our cross_entropy loss function \"\"\"\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIjNNYacZ9Qv"
   },
   "source": [
    "#### Check whether our network returns correct predictions and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cDdVlV8IZ9bo"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create a vector that tells us, whether the predictions from our net - y_conv\n",
    "    are equal to the correct digit labels - y. \"\"\"\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_l, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "\n",
    "\"\"\" Calculate the accurracy of correct predictions \"\"\"\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_yDuzfqcfRk"
   },
   "source": [
    "#### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOjWtD2Scm8R"
   },
   "source": [
    "The following code will train our network with using of our predefined Adam optimizer, based on the batch size equal to 64 and with 5000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R-bYBrMduNjf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, validation accuracy: 0.0989999994635582\n",
      "step: 100, validation accuracy: 0.10999999940395355\n",
      "step: 200, validation accuracy: 0.16599999368190765\n",
      "step: 300, validation accuracy: 0.1809999942779541\n",
      "step: 400, validation accuracy: 0.15700000524520874\n",
      "step: 500, validation accuracy: 0.19900000095367432\n",
      "step: 600, validation accuracy: 0.21799999475479126\n",
      "step: 700, validation accuracy: 0.2800000011920929\n",
      "step: 800, validation accuracy: 0.25\n",
      "step: 900, validation accuracy: 0.40400001406669617\n",
      "step: 1000, validation accuracy: 0.4300000071525574\n",
      "step: 1100, validation accuracy: 0.41100001335144043\n",
      "step: 1200, validation accuracy: 0.44600000977516174\n",
      "step: 1300, validation accuracy: 0.503000020980835\n",
      "step: 1400, validation accuracy: 0.49300000071525574\n",
      "step: 1500, validation accuracy: 0.5070000290870667\n",
      "step: 1600, validation accuracy: 0.5189999938011169\n",
      "step: 1700, validation accuracy: 0.5509999990463257\n",
      "step: 1800, validation accuracy: 0.5849999785423279\n",
      "step: 1900, validation accuracy: 0.6079999804496765\n",
      "step: 2000, validation accuracy: 0.574999988079071\n",
      "step: 2100, validation accuracy: 0.5879999995231628\n",
      "step: 2200, validation accuracy: 0.5979999899864197\n",
      "step: 2300, validation accuracy: 0.6110000014305115\n",
      "step: 2400, validation accuracy: 0.6309999823570251\n",
      "step: 2500, validation accuracy: 0.6370000243186951\n",
      "step: 2600, validation accuracy: 0.628000020980835\n",
      "step: 2700, validation accuracy: 0.6340000033378601\n",
      "step: 2800, validation accuracy: 0.6389999985694885\n",
      "step: 2900, validation accuracy: 0.6439999938011169\n",
      "step: 3000, validation accuracy: 0.640999972820282\n",
      "step: 3100, validation accuracy: 0.6259999871253967\n",
      "step: 3200, validation accuracy: 0.6150000095367432\n",
      "step: 3300, validation accuracy: 0.6060000061988831\n",
      "step: 3400, validation accuracy: 0.6129999756813049\n",
      "step: 3500, validation accuracy: 0.628000020980835\n",
      "step: 3600, validation accuracy: 0.6539999842643738\n",
      "step: 3700, validation accuracy: 0.6800000071525574\n",
      "step: 3800, validation accuracy: 0.6869999766349792\n",
      "step: 3900, validation accuracy: 0.6930000185966492\n",
      "step: 4000, validation accuracy: 0.6959999799728394\n",
      "step: 4100, validation accuracy: 0.7039999961853027\n",
      "step: 4200, validation accuracy: 0.7049999833106995\n",
      "step: 4300, validation accuracy: 0.7279999852180481\n",
      "step: 4400, validation accuracy: 0.7480000257492065\n",
      "step: 4500, validation accuracy: 0.7269999980926514\n",
      "step: 4600, validation accuracy: 0.7120000123977661\n",
      "step: 4700, validation accuracy: 0.7120000123977661\n",
      "step: 4800, validation accuracy: 0.7329999804496765\n",
      "step: 4900, validation accuracy: 0.7480000257492065\n",
      "test accuracy: 0.7490000128746033\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(5000):\n",
    "    batch = mnist.train.next_batch(64)\n",
    "    if i % 100 == 0:\n",
    "        validation_accuracy = accuracy.eval(feed_dict={\n",
    "          x: mnist.validation.images, y_l: mnist.validation.labels, keep_prob: 1.0})\n",
    "        print('step: {}, validation accuracy: {}'.format(i, round(validation_accuracy,3)))\n",
    "        train_step.run(feed_dict={x: batch[0], y_l: batch[1], keep_prob: 0.5})\n",
    "  print('test accuracy: {}'.format(round(accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images, y_l: mnist.test.labels, keep_prob: 1.0}),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tf.ipynb",
   "provenance": [
    {
     "file_id": "1aeSOutaNis8Fu_5w_U0U-mxYRCcJpa7M",
     "timestamp": 1518182135874
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
